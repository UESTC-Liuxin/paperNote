# MASK RCNN

## Abstract  

We present a conceptually simple, flexible, and general framework for object instance segmentation. Our approach efficiently detects objects in an image while simultaneously generating a high-quality segmentation mask for each instance. The method, called Mask R-CNN, extends Faster R-CNN by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. Mask R-CNN is simple to train and adds only a small overhead to Faster R-CNN, running at 5 fps. Moreover, Mask R-CNN is easy to generalize to other tasks, e.g., allowing us to estimate human poses in the same framework.We show top results in all three tracks of the COCO suite of challenges, including instance segmentation, boundingbox object detection, and person keypoint detection. Without bells and whistles, Mask R-CNN outperforms all existing, single-model entries on every task, including the COCO 2016 challenge winners. We hope our simple and effective approach will serve as a solid baseline and help ease future research in instance-level recognition. Code has been made available at: https://github.com/ facebookresearch/Detectron.

我们为对象实例分割提供了一个概念上简单，灵活且通用的框架。 我们的方法有效地检测图像中的对象，同时为每个实例生成高质量的分割蒙版。 该方法称为“MASK R-CNN”，它通过与现有的用于边界框识别的分支并行添加一个用于预测对象遮罩的分支，从而扩展了Faster R-CNN。 MASK R-CNN易于训练，并且以5 fps的速度向Faster R-CNN仅增加了很小的开销（**overhead**）。 此外，Mask R-CNN易于推广（**generalize**）到其他任务，例如，允许我们在同一框架中估计人体姿势。我们在所有COCO配套的挑战赛三个tracks中均表现出了最佳结果，包括实例分割，边界框对象检测， 和人员关键点检测。  Mask R-CNN不需花哨，在所有任务上都胜过所有现有的单一模型条目，包括2016年COCO挑战赛获奖者。 我们希望我们简单有效的方法将成为坚实的基准，并有助于简化（**ease**）实例级识别的未来研究。 代码已在以下位置提供：https：//github.com/facebookresearch/Detectron。

Instance segmentation is challenging because it requires the correct detection of all objects in an image while also precisely segmenting each instance. It therefore combines elements from the classical computer vision tasks of object detection, where the goal is to classify individual objects and localize each using a bounding box, and semantic segmentation, where the goal is to classify each pixel into a fixed set of categories without differentiating object instances.1 Given this, one might expect a complex method is required to achieve good results. However, we show that a surprisingly simple, flexible, and fast system can surpass prior state-of-the-art instance segmentation results.

实例分割具有挑战性，因为它需要正确检测图像中的所有对象，同时还要精确分割每个实例。 因此，它结合了对象检测的经典计算机视觉任务中的元素，其中目标是使用边界框对单个对象进行分类和定位，以及语义分割，目的是将每个像素分类为固定的类别集而无需区分 对象实例。1鉴于此，人们可能期望需要一种复杂的方法才能取得良好的效果。 但是，我们显示出令人惊讶的简单，灵活和快速的系统可以超越（**surpass**）现有（**prior**）的最新实例分割结果。

Our method, called Mask R-CNN, extends Faster R-CNN [36] by adding a branch for predicting segmentation masks on each Region of Interest (RoI), in parallel with the existing branch for classification and bounding box regression (Figure 1). The mask branch is a small FCN applied to each RoI, predicting a segmentation mask in a pixel-topixel manner. Mask R-CNN is simple to implement and train given the Faster R-CNN framework, which facilitates a wide range of flexible architecture designs. Additionally, the mask branch only adds a small computational overhead, enabling a fast system and rapid experimentation.

我们的方法称为Mask R-CNN，它==通过添加一个分支来预测每个关注区域（RoI）上的分割蒙版，从而扩展了Faster R-CNN [36]，与现有的用于分类和边界框回归的分支并行（图1）==  。 Mask分支是应用于每个RoI的小FCN，以像素到像素的方式预测分段遮罩。 有了Faster R-CNN框架，Mask R-CNN易于实施和训练，从而促进了多种灵活的体系结构设计。 此外，mask分支仅增加了少量的计算开销，从而实现了快速的系统和快速的实验。

In principle Mask R-CNN is an intuitive extension of Faster R-CNN, yet constructing the mask branch properly is critical for good results. Most importantly, Faster RCNN was not designed for pixel-to-pixel alignment between network inputs and outputs. This is most evident in how RoIPool [18, 12], the de facto core operation for attending to instances, performs coarse spatial quantization for feature extraction. To fix the misalignment, we propose a simple, quantization-free layer, called RoIAlign, that faithfully preserves exact spatial locations. Despite being a seemingly minor change, RoIAlign has a large impact: it improves mask accuracy by relative 10% to 50%, showing bigger gains under stricter localization metrics. Second, we found it essential to decouple mask and class prediction: we predict a binary mask for each class independently, without competition among classes, and rely on the network’s RoI classification branch to predict the category. In contrast, FCNs usually perform per-pixel multi-class categorization, which couples segmentation and classification, and based on our experiments works poorly for instance segmentation.

原则上，Mask R-CNN是Faster R-CNN的直观扩展，但正确构造Mask分支对于获得良好结果至关重要。 最重要的是，Faster RCNN并不是为网络输入和输出之间的像素到像素对齐而设计的。 这最明显地体现在RoIPool [18，12]如何处理实例的实际核心操作中，如何对特征提取进行粗略的空间(**spatial**)量化(**quantization**)。 ==为了解决未对准问题，我们提出了一个简单的无量化层，称为RoIAlign==，它忠实地保留了精确(**exact**)的空间位置。 尽管看似很小的变化，RoIAlign仍具有很大的影响：它将掩模的精度提高了10％至50％，在严格的本地化指标下显示出更大的收益。 其次，==我们发现将遮罩和类别预测分离开来是至关重要的：我们独立地预测每个类别的二进制掩码，而无需类别之间的竞争，并依靠网络的RoI分类分支预测类别==。 相比之下，FCN通常会按像素进行多类分类，这将分割和分类结合在一起，并且基于我们的实验，例如分割效果不佳。

Without bells and whistles, Mask R-CNN surpasses all previous state-of-the-art single-model results on the COCO instance segmentation task [28], including the heavilyengineered entries from the 2016 competition winner. As a by-product, our method also excels on the COCO object detection task. In ablation experiments, we evaluate multiple basic instantiations, which allows us to demonstrate its robustness and analyze the effects of core factors.

Mask R-CNN在没有花哨（**bells and whistles：华而不实的东西**）的情况下，在COCO实例分割任务[28]上超过了所有先前的最新单模型结果，包括2016年竞赛获胜者的精心设计的记录（entires）。 作为副产品，我们的方法还擅长（**excels**）于COCO对象检测任务。 在消融（**ablation**）实验中，我们评估了多个基本实例，这使我们能够证明其鲁棒性并分析核心因素的影响。

Our models can run at about 200ms per frame on a GPU, and training on COCO takes one to two days on a single 8-GPU machine. We believe the fast train and test speeds, together with the framework’s flexibility and accuracy, will benefit and ease future research on instance segmentation.

我们的模型在GPU上每帧的运行时间约为200毫秒，在一台8-GPU机器上进行COCO的培训需要一到两天。 我们认为，快速的培训和测试速度以及该框架的灵活性和准确性，将有益于并简化（**ease**）未来对实例细分的研究。

Finally, we showcase the generality of our framework via the task of human pose estimation on the COCO keypoint dataset [28]. By viewing each keypoint as a one-hot binary mask, with minimal modification Mask R-CNN can be applied to detect instance-specific poses. Mask R-CNN surpasses the winner of the 2016 COCO keypoint competition, and at the same time runs at 5 fps. Mask R-CNN, therefore, can be seen more broadly as a flexible framework for instance-level recognition and can be readily extended to more complex tasks.

最后，我们通过在COCO关键点数据集[28]上进行人体姿势估计来展示（**showcase**）我们框架的一般性。 通过将每个关键点视为一个ne-hot二进制掩码，只需进行最少的修改，即可将Mask R-CNN应用于检测特定于实例的姿势。  Mask R-CNN超越了2016年COCO关键点竞赛的获胜者，同时以5 fps的速度运行。 因此，Mask R-CNN可以更广泛地视为实例级别识别的灵活框架，并且可以轻松扩展到更复杂的任务。

## 2. Related Work 
**R-CNN:** The Region-based CNN (R-CNN) approach [13] to bounding-box object detection is to attend to a manageable number of candidate object regions [42, 20] and evaluate convolutional networks [25, 24] independently on each RoI. R-CNN was extended [18, 12] to allow attending to RoIs on feature maps using RoIPool, leading to fast speed and better accuracy. Faster R-CNN [36] advanced this stream by learning the attention mechanism with a Region Proposal Network (RPN). Faster R-CNN is flexible and robust to many follow-up improvements (e.g., [38, 27, 21]), and is the current leading framework in several benchmarks.

用于边界框对象检测的基于区域的CNN（R-CNN）方法[13]要处理可管理数量的候选对象区域[42、20]，并分别在每个RoI上评估卷积网络[25、24]。  R-CNN进行了扩展[18，12]，允许使用RoIPool参加功能图上的RoI，从而提高了速度和准确性。 Faster R-CNN [36]通过使用区域提议网（RPN）学习注意力机制来推进这一流程。 更快的R-CNN对许多后续改进（例如[38、27、21]）具有灵活性和鲁棒性，并且在多个基准测试中都是当前领先的框架。

**Instance Segmentation:** Driven by the effectiveness of RCNN, many approaches to instance segmentation are based on segment proposals. Earlier methods [13, 15, 16, 9] resorted to bottom-up segments [42, 2]. DeepMask [33] and following works [34, 8] learn to propose segment candidates, which are then classified by Fast R-CNN. In these methods, segmentation precedes recognition, which is slow and less accurate. Likewise, Dai et al. [10] proposed a complex multiple-stage cascade that predicts segment proposals from bounding-box proposals, followed by classification.Instead, our method is based on parallel prediction of masks and class labels, which is simpler and more flexible.

受RCNN有效性的驱动，实例分割的许多方法都基于segment proposals。 较早的方法[13、15、16、9]采取（**resorted**）自下而上的方法[42、2]。  DeepMask [33]和随后的工作[34，8]学习建议分割候选者，然后由Fast R-CNN对其进行分类。 在这些方法中，分割先于识别，然后再进行识别，速度较慢且准确性较低。 同样，戴等人[10]提出了一种复杂的多级级联方法，该方法从边界框建议书中预测分段建议书，然后进行分类。相反，我们的方法基于对掩码和类标签的并行预测，它更简单，更灵活。

Most recently, Li et al. [26] combined the segment proposal system in [8] and object detection system in [11] for “fully convolutional instance segmentation” (FCIS). The common idea in [8, 11, 26] is to predict a set of positionsensitive output channels fully convolutionally. These channels simultaneously address object classes, boxes, and masks, making the system fast. But FCIS exhibits systematic errors on overlapping instances and creates spurious edges (Figure 6), showing that it is challenged by the fundamental difficulties of segmenting instances.

最近，李等人 [26]结合了[8]中的分段提议系统和[11]中的对象检测系统，以实现“全卷积实例分割”（FCIS）。  [8、11、26]中的共同思想是完全卷积地预测一组位置敏感的输出通道。 这些通道同时处理对象类，框和遮罩，从而使系统快速运行。 但是FCIS在重叠的实例上表现出系统性错误并产生虚假边缘（图6），表明它受到分割实例的基本困难的挑战。

Another family of solutions [23, 4, 3, 29] to instance segmentation are driven by the success of semantic segmentation. Starting from per-pixel classification results (e.g., FCN outputs), these methods attempt to cut the pixels of the same category into different instances. In contrast to the segmentation-first strategy of these methods, Mask R-CNN is based on an instance-first strategy. We expect a deeper incorporation of both strategies will be studied in the future.

实例分割的另一类解决方案[23、4、3、29]是由语义分割的成功驱动的。 从按像素分类的结果（例如FCN输出）开始，这些方法尝试将相同类别的像素切成不同的实例。 与这些方法的分割优先策略相反，Mask R-CNN基于实例优先策略。 我们希望将来将对这两种策略进行更深入的研究。

## 3. Mask R-CNN 

   Mask R-CNN is conceptually simple: Faster R-CNN has two outputs for each candidate object, a class label and a bounding-box offset; to this we add a third branch that outputs the object mask. Mask R-CNN is thus a natural and intuitive idea. But the additional mask output is distinct from the class and box outputs, requiring extraction of much finer spatial layout of an object. Next, we introduce the key elements of Mask R-CNN, including pixel-to-pixel alignment, which is the main missing piece of Fast/Faster R-CNN