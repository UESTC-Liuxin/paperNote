# SPP Net

[TOC]

##  SPP Net的由来

[论文地址](https://arxiv.org/pdf/1406.4729.pdf)

[来自于北邮的一个小姐姐的翻译地址](https://blog.csdn.net/weixin_43624538/article/details/87966601)

[比较好的解释](https://www.jianshu.com/p/07a573035e43)

说到SPP Net就不得不提RCNN了，[RCNN](https://arxiv.org/pdf/1311.2524v3.pdf)的一般流程可以概括为：

1. 将输入图片进行resize;
2. 利用selective search 算法在图像中从上到下提取2000个左右的Region Proposal;
3. 将每个Region Proposal缩放(warp)成227*227的大小并输入到CNN，将CNN的fc7层的输出作为特征；
4. 将每个Region Proposal提取的CNN特征输入到SVM进行分类；
5. 对于SVM分好类的Region Proposal做边框回归，用Bounding box回归值校正原来的建议窗口，生成预测窗口坐标.

那么缺点非常明显：

1. 对每个Region Proposal都需要进行一次特征提取，Region Proposal在输入图像上是有大量重合区域的，因此计算是冗余的；

2. > 流行的CNNs都需要输入的图像尺寸是固定的（比如224×224），这限制了输入图像的长宽比和缩放尺度。当遇到任意尺寸的图像时，都是先将图像适应成固定尺寸，方法包括裁剪(crop)和变形(wrap)。**裁剪会导致信息的丢失，变形会导致位置信息的扭曲，就会影响识别的精度。另外，一个预先定义好的尺寸，在物体是缩放可变的时候就不适用了。固定尺寸，忽略了涉及比例(scale)的问题**

   ![](https://img-blog.csdnimg.cn/20190227094134367.png)

为了解决上面这两个问题，何恺明大神（*我：我想成为何恺明一样的男人；Nvidia：呸，你不配*）提出了SPP Net（**Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition** ）空间金字塔池化。

## SPP NET基本原理

**关于第一个问题的解决：**

从输入图像到特征图，应该只需要做一次提取特征的运算就可以了，为了避免重复区域的运算，在SPP中，提取特征的时候并不考虑region proposal，先对整个输入图像进行多次卷积得到特征图。然后重点来了，这里并没有在输入图像上产生region proposal，而是在最后的特征图上取region proposal。这样做的可行性在于：

> 我们注意到固定尺寸的要求，仅仅是因为全连接层的存在。另一方面，卷积层使用滑动的过滤器，它们的输出基本保持了原始输入的比例关系。它们的输出就是特征图[1]——它们不仅涉及响应的强度，还包括空间位置。

论文中的这一句话简单的说明了，虽然输入图像在进行了一系列的卷积操作变成feature map之后，ROI在图像中的空间分布还是一致的。如下图所示：

![](https://img-blog.csdnimg.cn/2019022709490310.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzYyNDUzOA==,size_16,color_FFFFFF,t_70)

> 图2中，我们可视化了一些特征图。这些特征图来自于conv5层的一些过滤器。图2（c）显示了ImageNet数据集中激活最强的若干图像。可以看到一个过滤器能够被一些语义内容激活。例如，第55个过滤器（图2，左下）对圆形十分敏感；第66层（图2，右上）对∧形状特别敏感；第118个过滤器（图2，右下）对V形状非常敏感。这些输入图像中的形状会激活相应位置的特征图（图2中的箭头）。值得注意的是，图2中生成的特征图并没有固定输入尺寸。深度卷积层生成的特征图和传统方法中的特征图很相似。这些传统方法中，SIFT向量或图像碎片被密集地抽取出来，在通过矢量量化，稀疏化或Fisher核函数进行编码。这些编码后的特征构成了特征图，然后通过词袋（BoW）或空间金字塔进行池化。类似的深度卷积的特征也可以这样做。

因此，直接在特征图取2000个region proposal（实际上与输入图像的位置存在一一映射关系，至于具体的解释，可以看这篇文章https://www.jianshu.com/p/07a573035e43）。就避免了重复提取特征，节省了大量的时间。

**关于第二个问题的解决：**

这个问题就是SPP NET的核心：**空间金字塔池化**。

由于常规CNN包括RCNN都避免不了fixed size这个问题，于是为了对任意输入的图像进行处理，SPP NET就利用空间金字塔池化来解决。如下图所示，不管输入图像的尺寸，对最后的特征图分别采用分块的形式（分成$4*4,2*2,1*1$块），然后在每一块上进行滑窗式最大池化，池化的通道数为256，最后形成（16+4+1）*256维的特征。

![](https://upload-images.jianshu.io/upload_images/6983308-4c9e719331f48634.png?imageMogr2/auto-orient/strip|imageView2/2/w/1020/format/webp)

（==注意：在目标检测中，并不是对于直接对整个特征图进行**空间金字塔池化**，而是对proposal进行，具体的操作如下：==）

> 1. 对于R-CNN，整个过程是：
>    - 通过选择性搜索，对待检测的图片进行搜索出~2000个候选窗口。
>    - 把这2k个候选窗口的图片都缩放到227*227，然后分别输入CNN中，每个proposal提取出一个特征向量，（即：利用CNN对每个proposal进行提取特征向量。）
>    - 把上面每个候选窗口的对应特征向量，利用SVM算法进行分类识别。 可以看出R-CNN的计算量是非常大的，因为2000个候选窗口都要输入到CNN中，分别进行特征提取。
> 2. 而对于SPP-Net，整个过程是：
>    - 首先通过选择性搜索，对待检测的图片进行搜索出2000个候选窗口。（这一步和R-CNN一样）- 
>    - 特征提取阶段。==区别！！ 这一步骤的具体操作如下：把整张待检测的图片，输入CNN中，进行一次性特征提取，得到特征图，然后在特征图中找到各个候选框的区域，再对各个候选框采用空间金字塔池化，提取出固定长度的特征向量。而R-CNN输入的是每个候选框，然后在进入CNN，因为SPP-Net只需要一次对整张图片进行特征提取，速度会大大提升。==
>    - 最后一步，采用SVM算法进行特征向量分类识别。